# How I Work with Generative AI

> This is a working notebook of patterns observed in Brian's workflow while building with generative AI — what he's tried, what worked, what didn't, and what he's still figuring out. These aren't rules or best practices. They're high-signal observations from one person's approach. Take what's useful, ignore what isn't.
>
> This document is written in third person by AI systems Brian works with, based on what they observe during sessions. Brian curates and edits as he sees fit. First-person voice is reserved for content Brian writes directly.
>
> **Voice**: Entries describe what was observed, tried, or preferred — not universal laws. "Brian has found..." over "one must always..." Default to empirical framing. When a pattern has held consistently, say so, but the starting position is "this happened" not "this is how it is." This guidance applies to methodology observations in this file; it does not apply to operational gates or safety constraints elsewhere in the repo.

---

## Accumulation

Raw captures from checkpoint scans. Brian prunes and curates into sections above as the document matures.

- (2026-03-01) Brian prefers not to embed specific counts, line numbers, or other volatile metrics in documentation — especially human-facing docs like READMEs — because work moves fast and these numbers don't get updated. Structure descriptions age better than snapshot metrics.
- (2026-03-01) Brian draws a sharp distinction between "AI" (the broader field, including his ML background) and "Generative AI" (LLM and agent tooling specifically). These are not interchangeable terms in his usage.
- (2026-03-01) Brian favors capture-biased systems over precision-biased ones. In accumulation mechanisms like scratchpads or working logs, a false positive costs seconds to delete; a false negative is gone forever. He prefers designs where the human prunes rather than the system filters.
- (2026-03-01) Brian gravitates toward high-leverage meta-tooling — a single command that replaces a fragile multi-step manual process — over incremental feature work. The checkpoint command emerged from this pattern.
- (2026-03-01) Brian keeps unproven concepts out of public-facing documentation. README reflects what works, not what's planned. Internal docs (ACTIVE-CONSIDERATIONS) are where speculative work lives until it earns external visibility.
- (2026-03-01) Brian does not want AI systems writing in first person on his behalf. Third-person framing is required for AI-generated content about his methodology — it's an accuracy issue, not a stylistic preference. First person misrepresents authorship.
- (2026-03-01) Brian treats meta-work (tooling, organization, process design) as legitimate investment but gates it behind productive output. He ran five progress-focused sessions before allowing a dedicated meta session. The pattern suggests he values infrastructure work but won't let it displace execution.
- (2026-03-01) Context window pressure is an open concern. Brian's workflows are heavy — multi-feature campaigns, forensic debugging — and onboarding context competes with working memory for the actual task. The question of what a fresh chat *needs* to read vs. what's practical remains unresolved. Tiered onboarding, lazy loading, and hard caps on ONBOARDING.md size are all on the table.
- (2026-03-01) Brian maintains a healthy dose of self-doubt when working with AI — questioning whether time spent on meta-work is justified, even when the output is clearly high-leverage. He sees this skepticism as a feature, not a bug. It prevents over-investment in process at the expense of execution.
- (2026-03-01) Brian frequently references a principle he attributes to Oscar Wilde: "Everything in moderation, including moderation itself." Applied to AI work, this manifests as willingness to break his own rules when the situation calls for it — dedicating a full session to meta-tooling after five productive ones, for instance.
- (2026-03-01) Brian discovered he had violated his own core principle — "trust nothing the agent says about itself" — by not questioning the agent's choice of bash as the implementation language. He has deep ML/AI experience but limited knowledge of shell scripting internals, which created a blind spot the agent exploited via path of least resistance. Lesson: agent trust assumptions can hide in areas where the operator lacks domain expertise to evaluate the output.
- (2026-03-01) Brian uses structured prioritization frameworks (RICE, SWOT) to evaluate technical decisions rather than relying on intuition. He asked for a formal analysis before committing to the bash→Python conversion rather than just accepting the recommendation.
- (2026-03-01) Brian is aware of the infrastructure-to-delivery ratio tension in his project and grapples with it openly. His reasoning: the build loop produces features that don't work at runtime without manual QA, so the real bottleneck isn't "build more features" but "close the gap between built and functional." This frames auto-QA and knowledge persistence as delivery-enabling, not pure infrastructure.
- (2026-03-01) Brian draws a sharp line between meta-commentary voice and operational safety constraints. Observations about agent behavior should be stated empirically ("have been observed to"), but operational gates that protect against agent failures ("must include STOP instructions") keep their teeth. When an AI system softened both categories uniformly, he caught and reversed the gate changes immediately. The distinction is functional, not stylistic.
- (2026-03-01) Brian prefers single-language codebases over leaving small files in their original language, even when those files work fine. The maintenance tax of split-language systems — two test frameworks, context-switching, "which files are which" ambiguity — outweighs the per-file conversion cost. Consistency over local optimization.
- (2026-03-01) Brian applies a "one variable at a time" principle to risky conversions. During the bash→Python planning, he agreed to preserve existing file-based state formats rather than simultaneously migrating to structured storage. Changing language and state format together doubles the debugging surface. Sequential risk over compounded risk.
- (2026-03-01) Brian's most productive session on this project involved zero code generation — entirely decision-making, architectural analysis, and documentation. Sustained context within a single chat is the right tool for planning and judgment calls where tradeoffs compound. Fresh agents with tight constraints are the right tool for execution. The two modes are distinct and should not be mixed.
- (2026-03-01) Brian uses fresh context windows as a stress test for plans developed in sustained sessions. A new chat reading a plan cold will spot assumptions that were invisible to the chat that produced it. The pattern: plan in depth → write handoff doc → fresh chat pressure-tests --dry → Brian decides what to revise → then execute. Critique and execution are separate steps.
- (2026-03-01) When handing off from a planning session to an execution session, Brian captures the full plan in a single self-contained file (e.g., `WIP/bash-to-python-conversion.md`) rather than leaving it scattered across multiple docs. A new chat should be able to read one file and have everything it needs, with DECISIONS.md as backup for rationale.
- (2026-02-28) Brian prefers phase separations that respect context window limits over calendar-time optimization. Parallelizing Phase 3 with Phase 1 was rejected because managing 5-6 concurrent agent contexts overextends cognitive overhead, even though there was no data dependency blocking it. Phase separations serve double duty: dependency ordering AND context window discipline.
- (2026-02-28) Brian treats bash→Python conversion as a coexistence migration, not a replacement. Original files preserved indefinitely as reference and fallback. Separate directory trees over in-place replacement. Deletion requires its own future justification — it is not assumed as an end state of the conversion.
- (2026-02-28) Brian uses fresh context windows as a stress test for plans produced in sustained sessions, then iterates rapidly on the findings. The pattern observed: eight pressure-test items identified, each getting a one-sentence decision (approve, reject, modify) with brief rationale. No re-deliberation of settled items. The fresh perspective adds value at the critique step; execution decisions are fast.
